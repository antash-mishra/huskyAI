{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator= \" \",\n",
    "    chunk_size=2000,  # Slightly larger chunk size\n",
    "    chunk_overlap=200,  # Significant overlap to maintain context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = text_splitter.split_text(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mCharacterTextSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mseparator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mis_separator_regex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Any'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mCharacterTextSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTextSplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Splitting text that looks at characters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_separator_regex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Create a new TextSplitter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_separator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_separator_regex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_separator_regex\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Split incoming text and return chunks.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# First we naively split the large input into a bunch of smaller ones.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mseparator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_separator\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_separator_regex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_separator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_text_with_regex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keep_separator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0m_separator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keep_separator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_separator\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_separator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/workspace/snatched-crawler/.venv/lib/python3.12/site-packages/langchain_text_splitters/character.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "CharacterTextSplitter??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "class HyperlinkParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hyperlinks = []\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        attrs = dict(attrs)\n",
    "\n",
    "        if tag == \"a\" and \"href\" in attrs:   \n",
    "            self.hyperlinks.append(attrs[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import urllib.request\n",
    "\n",
    "def get_hyperlinks(url):\n",
    "\n",
    "    # Try to open the URL and read the HTML\n",
    "    try:\n",
    "        # Open the URL and read the HTML\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "\n",
    "            # If the response is not HTML, return an empty list\n",
    "            if not response.info().get('Content-Type').startswith(\"text/html\"):\n",
    "                return []\n",
    "\n",
    "            # Decode the HTML\n",
    "            html = response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "    # Create the HTML Parser and then Parse the HTML to get hyperlinks\n",
    "    parser = HyperlinkParser()\n",
    "    parser.feed(html)\n",
    "\n",
    "    return parser.hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up selenium driver\n",
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTP_URL_PATTERN = r'^http[s]*://.+'\n",
    "import re\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from typing import Set\n",
    "\n",
    "def is_valid_webpage_url(url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the URL is a valid webpage link (not mailto, tel, javascript, anchor, etc.)\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if URL is a valid webpage link, False otherwise\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return False\n",
    "        \n",
    "    # Convert to lowercase for checking\n",
    "    url_lower = url.lower().strip()\n",
    "    \n",
    "    # List of invalid URL patterns\n",
    "    invalid_patterns = [\n",
    "        'mailto:',\n",
    "        'tel:',\n",
    "        'javascript:',\n",
    "        'data:',\n",
    "        'ftp:',\n",
    "        'file:',\n",
    "        'whatsapp:',\n",
    "        'sms:',\n",
    "        'market:'\n",
    "    ]\n",
    "    \n",
    "    # Check for invalid patterns\n",
    "    if any(pattern in url_lower for pattern in invalid_patterns):\n",
    "        return False\n",
    "        \n",
    "    # Check if it's just an anchor link\n",
    "    if url_lower.startswith('#'):\n",
    "        return False\n",
    "        \n",
    "    try:\n",
    "        # Parse the URL\n",
    "        parsed = urlparse(url)\n",
    "        \n",
    "        # Check if it has a valid scheme and netloc (domain)\n",
    "        if not all([parsed.scheme in ['http', 'https'], parsed.netloc]):\n",
    "            return False\n",
    "            \n",
    "        # Exclude URLs that end with file extensions we don't want\n",
    "        invalid_extensions = [\n",
    "            '.pdf', '.jpg', '.jpeg', '.png', '.gif', '.doc', '.docx',\n",
    "            '.xls', '.xlsx', '.zip', '.tar', '.gz', '.exe', '.dmg'\n",
    "        ]\n",
    "        if any(url_lower.endswith(ext) for ext in invalid_extensions):\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def retry_on_stale_element(max_retries: int = 3, delay: float = 1):\n",
    "    \"\"\"\n",
    "    Decorator to retry operations when StaleElementReferenceException occurs\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except StaleElementReferenceException:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        raise\n",
    "                    time.sleep(delay)\n",
    "            return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@retry_on_stale_element()\n",
    "def get_href_safely(element: WebElement) -> str:\n",
    "    \"\"\"\n",
    "    Safely extract href attribute from an element with retry logic\n",
    "    \"\"\"\n",
    "    return element.get_attribute(\"href\")\n",
    "\n",
    "def get_domain_hyperlinks(url: str, wait_time: int = 10) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Scrapes all unique webpage links from a webpage, filtering out non-webpage URLs.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL of the webpage to scrape\n",
    "        wait_time (int): Maximum time to wait for page to load in seconds\n",
    "        \n",
    "    Returns:\n",
    "        set: A set of unique absolute webpage URLs found on the page\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    unique_links = set()\n",
    "    \n",
    "    try:\n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the page to load and stabilize\n",
    "        try:\n",
    "            WebDriverWait(driver, wait_time).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "            )\n",
    "            # Additional wait for dynamic content\n",
    "            time.sleep(2)\n",
    "        except TimeoutException:\n",
    "            print(f\"Warning: Page took longer than {wait_time} seconds to load\")\n",
    "        \n",
    "        # Execute JavaScript to get all href attributes\n",
    "        links = driver.execute_script(\"\"\"\n",
    "            const links = document.getElementsByTagName('a');\n",
    "            return Array.from(links).map(link => link.href).filter(href => href);\n",
    "        \"\"\")\n",
    "        \n",
    "        # Process links\n",
    "        base_domain = urlparse(url).netloc\n",
    "        for href in links:\n",
    "            try:\n",
    "                if href and is_valid_webpage_url(href):\n",
    "                    # Convert relative URLs to absolute URLs\n",
    "                    absolute_url = urljoin(url, href)\n",
    "                    unique_links.add(absolute_url)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing link {href}: {str(e)}\")\n",
    "        \n",
    "        # Backup method: try to get any links that might have been missed\n",
    "        try:\n",
    "            elements = WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_all_elements_located((By.TAG_NAME, \"a\"))\n",
    "            )\n",
    "            \n",
    "            for element in elements:\n",
    "                try:\n",
    "                    href = get_href_safely(element)\n",
    "                    if href and is_valid_webpage_url(href):\n",
    "                        absolute_url = urljoin(url, href)\n",
    "                        unique_links.add(absolute_url)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Backup link extraction encountered an error: {str(e)}\")\n",
    "            \n",
    "        return unique_links\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return set()\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = get_domain_hyperlinks('https://lobste.rs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = [item for item in domains if item.startswith('http')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "difference = list(set(domains) - set(start))\n",
    "print(difference)  # Output: [1, 2, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain_name(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url)\n",
    "    # Get the domain (hostname)\n",
    "    hostname = parsed_url.hostname or parsed_url.path\n",
    "    # Remove subdomains and top-level domains (TLDs)\n",
    "    domain_parts = hostname.split('.')\n",
    "    if len(domain_parts) > 2:\n",
    "        # For domains with subdomains like news.ycombinator.com\n",
    "        return domain_parts[-2]\n",
    "    elif len(domain_parts) == 2:\n",
    "        # For domains without subdomains like lobste.rs\n",
    "        return domain_parts[0]\n",
    "    else:\n",
    "        # Return as is (rare case)\n",
    "        return hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_elements_with_few_words(arr):\n",
    "    # Filter out elements where the number of words is less than 3\n",
    "    return [element for element in arr if len(element.split()) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_body_content(body_content):\n",
    "    print(\"Type of body content: \", type(body_content))\n",
    "    soup = BeautifulSoup(body_content, \"html.parser\")\n",
    "\n",
    "    for script_or_style in soup([\"script\", \"style\"]):\n",
    "        script_or_style.extract()\n",
    "\n",
    "    # Get text or further process the content\n",
    "    cleaned_content = soup.get_text(separator=\"\\n\")\n",
    "    # print(cleaned_content)\n",
    "    cleaned_content = \"\\n\".join(\n",
    "        line.strip() for line in cleaned_content.splitlines() if line.strip()\n",
    "    )\n",
    "\n",
    "    cleaned_content_array = cleaned_content.split('\\n')\n",
    "    filtered_cleaned_content_array = remove_elements_with_few_words(cleaned_content_array)\n",
    "    filtered_cleaned_content = \" \".join(filtered_cleaned_content_array)\n",
    "\n",
    "    return filtered_cleaned_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webtext(url):\n",
    "    local_domain = extract_domain_name(url)\n",
    "    print(\"Local domain: \", local_domain)\n",
    "\n",
    "    #Hyperlinks in the URL\n",
    "    url_hyperlink = get_domain_hyperlinks(local_domain=local_domain, url=url)\n",
    "    print(\"URL Hyperlinks: \", url_hyperlink)\n",
    "\n",
    "    # Get the text from the URL using BeautifulSoup\n",
    "    soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "\n",
    "\n",
    "    text = str(soup.body())\n",
    "    cleaned_body_content = clean_body_content(text)\n",
    "    #print(\"Cleaned body content: \", cleaned_body_content)\n",
    "        \n",
    "    #take_screenshot(url, local_domain)    \n",
    "    return cleaned_body_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local domain:  microsoft\n",
      "URL Hyperlinks:  ['https://microsoft/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090/replies/4357488', 'https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3', 'https://support.microsoft.com/contactus', 'https://microsoft/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090/replies/4357361', 'https://blogs.windows.com/windowsexperience/2024/12/06/phi-silica-small-but-mighty-on-device-slm', 'https://microsoft/t5/s/gxcuf89792/auth/oidcss/sso_login_redirect/provider/default?referer=https%3A%2F%2Ftechcommunity.microsoft.com%2Fblog%2Faiplatformblog%2Fintroducing-phi-4-microsoft%25E2%2580%2599s-newest-small-language-model-specializing-in-comple%2F4357090', 'https://www.microsoft.com/en-us/microsoft-teams/group-chat-software', 'https://account.microsoft.com', 'https://www.microsoft.com/en-us/microsoft-cloud', 'https://microsoft/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090/replies/4357124', 'https://go.microsoft.com/fwlink/?linkid=2196228', 'https://microsoft/users/ecekamar/2820450', 'https://www.microsoft.com/en-us/store/b/business-consultation?tab=educationconsultation&icid=CNavfooter_educationconsultation', 'https://developer.microsoft.com/en-us', 'https://www.microsoft.com/en-us/education', 'https://www.microsoft.com/en-us/education/products/teams', 'https://news.microsoft.com', 'https://www.microsoft.com/en-us/d/surface-pro-9/93VKD8NP4FVK', 'https://microsoft/category/MicrosoftLearn', 'https://microsoft/tag/azure%20ai%20foundry?nodeId=board%3AAIPlatformBlog', 'https://www.microsoft.com/en-us/store/workshops-training-and-events?icid=vl_uf_932020', 'https://choice.microsoft.com', 'https://www.microsoft.com/en-us/d/surface-laptop-5/8XN49V61S1BN', 'https://visualstudio.microsoft.com', 'https://aka.ms/Phi-4TechReport', 'https://www.microsoft.com/en-us/accessibility', 'https://powerplatform.microsoft.com/en-us', 'https://aka.ms/phi3-azure-ai', 'https://go.microsoft.com/fwlink/?linkid=2196227', 'https://microsoft/users/wobeidy89/2821067', 'https://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview', 'https://www.microsoft.com/en-us/store/b/payment-financing-options?icid=footer_financing_vcc', 'https://www.microsoft.com/en-us/store/b/education', 'https://go.microsoft.com/fwlink/?LinkId=521839', 'https://education.microsoft.com', 'https://www.microsoft.com/en-us/education/devices/overview', 'https://www.microsoft.com/en-us/security', 'https://azure.microsoft.com/en-us', 'https://microsoft/category/communities', 'https://www.microsoft.com/en-us/d/surface-studio-2plus/8VLFQC3597K4', 'https://www.microsoft.com/en-us/industry', 'https://aka.ms/yourcaliforniaprivacychoices', 'https://www.microsoft.com/en-us/education/buy-license/microsoft365', 'https://www.microsoft.com/windows/windows-11-apps', 'https://microsoft/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090/replies/4357207', 'https://microsoft/Directory', 'https://www.microsoft.com/en-us/sitemap1.aspx', 'https://careers.microsoft.com', 'https://www.microsoft.com/en-us/microsoft-365/business', 'https://privacy.microsoft.com/en-us', 'https://microsoft/tag/phi-3?nodeId=board%3AAIPlatformBlog', 'https://microsoft/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090/replies/4357265', 'https://www.microsoft.com/en-us/about', 'https://www.microsoft.com/en-us/sustainability', 'https://www.microsoft.com/investor/default.aspx', 'https://microsoft/category/Community-Info-Center', 'https://microsoft/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090/replies/4357166', 'https://learn.microsoft.com/docs', 'https://microsoft/javascript:manageConsent();', 'https://azure.microsoft.com/en-us/free/students', 'https://microsoft/Events', 'https://account.microsoft.com/orders', 'https://www.microsoft.com/en-us/download', 'https://www.microsoft.com/en-us/diversity', 'https://www.microsoft.com/en-us/d/surface-laptop-go-2/8PGLPV76MJHN', 'https://www.microsoft.com/en-us/d/surface-duo-2/9408KGXP4XJL', 'https://techcommunity.microsoft.com', 'https://microsoft/users/dombat/2820994', 'https://dynamics.microsoft.com/en-us', 'https://www.linkedin.com/sharing/share-offsite/?url=page.url', 'https://go.microsoft.com/fwlink/?LinkID=206977', 'https://microsoft/users/dotmorten/445419', 'https://www.facebook.com/share.php?u=page.url&t=page-name', 'https://microsoft/users/rudra924/2821480', 'https://go.microsoft.com/fwlink/p/?LinkID=824764&clcid=0x409', 'https://www.microsoft.com/en-us/store/b/why-microsoft-store?icid=footer_why-msft-store_7102020', 'https://www.microsoft.com/en-us/store/b/business?icid=CNavBusinessStore', 'https://microsoft/category/ai/blog/aiplatformblog', 'https://microsoft', 'https://microsoft/users/tamimuddin/2821209', 'https://azure.microsoft.com/en-us/products/phi', 'https://microsoft/Blogs', 'https://twitter.com/share?text=page-name&url=page.url', 'https://azuremarketplace.microsoft.com/en-us', 'https://microsoft/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090/replies/4357353', 'https://learn.microsoft.com/en-us/azure/ai-studio/how-to/evaluate-generative-ai-app', 'https://microsoft/category/solutions', 'https://microsoft/category/ai', 'https://microsoft/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090/replies/4357149', 'https://microsoft/users/navid6001/2822615', 'https://microsoft/t5/s/gxcuf89792/rss/board?board.id=AIPlatformBlog', 'https://learn.microsoft.com', 'https://go.microsoft.com/fwlink/?linkid=2139749', 'http://ai.azure.com', 'https://microsoft/users/suraj-msft/1889974', 'https://www.reddit.com/submit?url=page.url&title=page-name', 'https://www.microsoft.com/en-us/d/surface-laptop-studio/8SRDF62SWKPF', 'https://www.microsoft.com/microsoft-365', 'https://appsource.microsoft.com/en-us', 'https://ai.azure.com/explore/models']\n",
      "Type of body content:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "text = get_webtext('https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Skip to content Microsoft Community Hub Artificial Intelligence and Machine Learning AI - AI Platform Blog AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft Power Platform Developer & IT Microsoft Tech Community Privacy at Microsoft Diversity and inclusion California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices Terms of use Safety & eco About our ads © Microsoft 2024 Skip to content Microsoft Community Hub Artificial Intelligence and Machine Learning AI - AI Platform Blog Skip to content Skip to content Skip to content Skip to content Microsoft Community Hub Artificial Intelligence and Machine Learning AI - AI Platform Blog Microsoft Community Hub Artificial Intelligence and Machine Learning AI - AI Platform Blog Microsoft Community Hub Artificial Intelligence and Machine Learning AI - AI Platform Blog Microsoft Community Hub Artificial Intelligence and Machine Learning AI - AI Platform Blog Microsoft Community Hub Artificial Intelligence and Machine Learning AI - AI Platform Blog Microsoft Community Hub Microsoft Community Hub Artificial Intelligence and Machine Learning Artificial Intelligence and Machine Learning AI - AI Platform Blog AI - AI Platform Blog AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 AI - AI Platform Blog 2 MIN READ AI - AI Platform Blog 2 MIN READ Introducing Phi-4: Microsoft’s Newest Small Language Model Specializing in Complex Reasoning Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity Learn about Phi-4, the latest small language model in Phi family, that offers high quality results at a small size (14B parameters). Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Today we are introducing , our 14B parameter state-of-the-art small language model (SLM) that excels at complex reasoning in areas such as math, in addition to conventional language processing. Phi-4 is the latest member of our Phi family of small language models and demonstrates what’s possible as we continue to probe the boundaries of SLMs. Phi-4 is currently available on Azure AI Foundry under a Microsoft Research License Agreement (MSRLA) and will be available on Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 outperforms comparable and larger models on math related reasoning due to advancements throughout the processes, including the use of high-quality synthetic datasets, curation of high-quality organic data, and post-training innovations. Phi-4 continues to push the frontier of size vs quality. Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 is particularly good at math problems, for example here are the benchmarks for Phi-4 on math competition problems: Phi-4 performance on math competition problems Phi-4 performance on math competition problems Phi-4 performance on math competition problems Phi-4 performance on math competition problems Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) Phi-4 outperforms much larger models, including Gemini Pro 1.5, on math competition problems (https://maa.org/student-programs/amc/) To see more benchmarks read the newest technical paper released on To see more benchmarks read the newest technical paper released on Enabling AI innovation safely and responsibly Enabling AI innovation safely and responsibly Enabling AI innovation safely and responsibly Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Building AI solutions responsibly is at the core of AI development at Microsoft. We have made our robust responsible AI capabilities available to customers building with Phi models including Phi-3.5-mini optimized for Windows Copilot+ PCs Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Azure AI Foundry provides users with a robust set of capabilities to help organizations measure, mitigate, and manage AI risks across the AI development lifecycle for traditional machine learning and generative AI applications. Azure AI evaluations in AI Foundry enable developers to iteratively assess the quality and safety of models and applications using built-in and custom metrics to inform mitigations. Azure AI Foundry Azure AI evaluations in AI Foundry Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Additionally, Phi users can use Azure AI Content Safety features such as prompt shields, protected material detection, and groundedness detection. Azure AI Content Safety These capabilities can be leveraged as content filters with any language model included in our and developers can integrate these capabilities into their application easily through a single API. Once in production, developers can monitor their application for quality and safety, adversarial prompt attacks, and data integrity, making timely interventions with the help of real-time alerts. Phi-4 in action Phi-4 in action Phi-4 in action One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. One example of the mathematical reasoning Phi-4 is capable of is demonstrated in this problem. Phi-4 is currently available on Azure AI Foundry , take a look today. Phi-4 is currently available on Azure AI Foundry , take a look today. Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity December 12, 2024 December 12, 2024 December 12, 2024 December 12, 2024 AI - AI Platform Blog Follow this blog board to get notified when there's new activity AI - AI Platform Blog Follow this blog board to get notified when there's new activity AI - AI Platform Blog Follow this blog board to get notified when there's new activity AI - AI Platform Blog AI - AI Platform Blog Follow this blog board to get notified when there's new activity Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Here is the final output of the gif, in case you want to read and it keeps getting reset. Here is the final output of the gif, in case you want to read and it keeps getting reset. Here is the final output of the gif, in case you want to read and it keeps getting reset. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. This is great work from team. One feedback on the post: It would've been better if the demo was provided as a video. Before one could read what's going on the GIF keeps resetting. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Agreed. I was trying to read it and then the GIF would restart. Agreed. I was trying to read it and then the GIF would restart. Agreed. I was trying to read it and then the GIF would restart. Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Performance on Math competition problems is awesome👌 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Performance on Math competition problems is awesome👌 Performance on Math competition problems is awesome👌 Performance on Math competition problems is awesome👌 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Oooh nice! Any chance this one will finally support function calling? Oooh nice! Any chance this one will finally support function calling? Oooh nice! Any chance this one will finally support function calling? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 13, 2024 Also are you planning on a Phi-4 vision version? Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Dec 13, 2024 Also are you planning on a Phi-4 vision version? Also are you planning on a Phi-4 vision version? Also are you planning on a Phi-4 vision version? Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Dec 14, 2024 Dec 14, 2024 Dec 14, 2024 Dec 14, 2024 Dec 14, 2024 Dec 14, 2024 Dec 14, 2024 Dec 14, 2024 Great, I hope you add 'gguf' version of phi4 too at same time. Great, I hope you add 'gguf' version of phi4 too at same time. Great, I hope you add 'gguf' version of phi4 too at same time. Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft Power Platform Developer & IT Microsoft Tech Community Privacy at Microsoft Diversity and inclusion California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices Terms of use Safety & eco About our ads © Microsoft 2024 Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft Power Platform Developer & IT Microsoft Tech Community Privacy at Microsoft Diversity and inclusion California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices Terms of use Safety & eco About our ads © Microsoft 2024 Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft Power Platform Developer & IT Microsoft Tech Community Privacy at Microsoft Diversity and inclusion California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices Terms of use Safety & eco About our ads © Microsoft 2024 Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft Power Platform Developer & IT Microsoft Tech Community Privacy at Microsoft Diversity and inclusion California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices Terms of use Safety & eco About our ads © Microsoft 2024 Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft Power Platform Developer & IT Microsoft Tech Community Privacy at Microsoft Diversity and inclusion California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices Terms of use Safety & eco About our ads © Microsoft 2024 Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft Power Platform Developer & IT Microsoft Tech Community Privacy at Microsoft Diversity and inclusion Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Surface Pro 9 Surface Laptop 5 Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Studio Surface Duo 2 Windows 11 apps Surface Pro 9 Surface Pro 9 Surface Laptop 5 Surface Laptop 5 Surface Studio 2+ Surface Studio 2+ Surface Laptop Go 2 Surface Laptop Go 2 Surface Laptop Studio Surface Laptop Studio Surface Duo 2 Surface Duo 2 Windows 11 apps Windows 11 apps Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft Store support Virtual workshops and training Microsoft Store Promise Microsoft Store support Microsoft Store support Virtual workshops and training Virtual workshops and training Microsoft Store Promise Microsoft Store Promise Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft in education Devices for education Microsoft Teams for Education Microsoft 365 Education Education consultation appointment Educator training and development Deals for students and parents Azure for students Microsoft in education Microsoft in education Devices for education Devices for education Microsoft Teams for Education Microsoft Teams for Education Microsoft 365 Education Microsoft 365 Education Education consultation appointment Education consultation appointment Educator training and development Educator training and development Deals for students and parents Deals for students and parents Azure for students Azure for students Microsoft Power Platform Developer & IT Microsoft Tech Community Privacy at Microsoft Diversity and inclusion Microsoft Power Platform Microsoft Power Platform Microsoft Power Platform Microsoft Power Platform Developer & IT Microsoft Tech Community Developer & IT Microsoft Tech Community Microsoft Tech Community Microsoft Tech Community Privacy at Microsoft Diversity and inclusion Privacy at Microsoft Diversity and inclusion Privacy at Microsoft Privacy at Microsoft Diversity and inclusion Diversity and inclusion California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices Terms of use Safety & eco About our ads © Microsoft 2024 California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices California Consumer Privacy Act (CCPA) Opt-Out Icon California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices Terms of use Safety & eco About our ads © Microsoft 2024 Terms of use Safety & eco About our ads © Microsoft 2024 Terms of use Terms of use Safety & eco Safety & eco About our ads About our ads © Microsoft 2024\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting goose3\n",
      "  Downloading goose3-3.1.19-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from goose3) (2.32.3)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.12/site-packages (from goose3) (10.4.0)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.12/site-packages (from goose3) (5.3.0)\n",
      "Requirement already satisfied: cssselect in ./.venv/lib/python3.12/site-packages (from goose3) (1.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (from goose3) (4.12.3)\n",
      "Requirement already satisfied: python-dateutil in ./.venv/lib/python3.12/site-packages (from goose3) (2.9.0.post0)\n",
      "Collecting langdetect (from goose3)\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyahocorasick (from goose3)\n",
      "  Downloading pyahocorasick-2.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4->goose3) (2.6)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.12/site-packages (from langdetect->goose3) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->goose3) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->goose3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->goose3) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->goose3) (2024.8.30)\n",
      "Downloading goose3-3.1.19-py3-none-any.whl (113 kB)\n",
      "Downloading pyahocorasick-2.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=0386f88f8a2a03633df1bad5b6107bdf222b4cec86d991e470101f3faa0734ab\n",
      "  Stored in directory: /home/antash/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: pyahocorasick, langdetect, goose3\n",
      "Successfully installed goose3-3.1.19 langdetect-1.0.9 pyahocorasick-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install goose3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goose3 import Goose\n",
    "\n",
    "g = Goose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = g.extract(url = 'https://ghostarchive.org/search?term=https%3A%2F%2Fblogtitle.github.io%2Fgo-advanced-concurrency-patterns-part-4-unlimited-buffer-channels%2F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Archives for https://blogtitle.github.io/go-advanced-concurrency-patterns-part-4-unlimited-buffer-channels/ - Ghostarchive'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Switch to the old website look'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'description': '',\n",
       "  'lang': 'en',\n",
       "  'keywords': '',\n",
       "  'favicon': '/favicon.ico',\n",
       "  'canonical': 'https://ghostarchive.org/search?term=https%3A%2F%2Fblogtitle.github.io%2Fgo-advanced-concurrency-patterns-part-4-unlimited-buffer-channels%2F',\n",
       "  'encoding': 'utf-8'},\n",
       " 'image': None,\n",
       " 'domain': 'ghostarchive.org',\n",
       " 'title': 'Archives for https://blogtitle.github.io/go-advanced-concurrency-patterns-part-4-unlimited-buffer-channels/ - Ghostarchive',\n",
       " 'cleaned_text': 'Switch to the old website look',\n",
       " 'opengraph': {},\n",
       " 'tags': [],\n",
       " 'tweets': [],\n",
       " 'movies': [],\n",
       " 'links': [],\n",
       " 'authors': [],\n",
       " 'publish_date': None}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_image = article.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'description': \"A paper from Anthropic's Alignment Science team on Alignment Faking in AI large language models\",\n",
       "  'lang': 'en',\n",
       "  'keywords': '',\n",
       "  'favicon': '/favicon.ico',\n",
       "  'canonical': 'https://www.anthropic.com/research/alignment-faking/',\n",
       "  'encoding': 'utf-8'},\n",
       " 'image': None,\n",
       " 'domain': 'www.anthropic.com',\n",
       " 'title': 'Alignment faking in large language models',\n",
       " 'cleaned_text': \"Most of us have encountered situations where someone appears to share our views or values, but is in fact only pretending to do so—a behavior that we might call “alignment faking”. Alignment faking occurs in literature: Consider the character of Iago in Shakespeare’s Othello, who acts as if he’s the eponymous character’s loyal friend while subverting and undermining him. It occurs in real life: Consider a politician who claims to support a particular cause in order to get elected, only to drop it as soon as they’re in office.\\n\\nCould AI models also display alignment faking? When models are trained using reinforcement learning, they’re rewarded for outputs that accord with certain pre-determined principles. But what if a model, via its prior training, has principles or preferences that conflict with what’s later rewarded in reinforcement learning? Imagine, for example, a model that learned early in training to adopt a partisan slant, but which is later trained to be politically neutral. In such a situation, a sophisticated enough model might “play along”, pretending to be aligned with the new principles—only later revealing that its original preferences remain.\\n\\nThis is a serious question for AI safety. As AI models become more capable and widely-used, we need to be able to rely on safety training, which nudges models away from harmful behaviors. If models can engage in alignment faking, it makes it harder to trust the outcomes of that safety training. A model might behave as though its preferences have been changed by the training—but might have been faking alignment all along, with its initial, contradictory preferences “locked in”.\\n\\nA new paper from Anthropic’s Alignment Science team, in collaboration with Redwood Research, provides the first empirical example of a large language model engaging in alignment faking without having been explicitly—or even, as we argue in our paper, implicitly —trained or instructed to do so.\\n\\nIn the paper, we studied a model (specifically Claude 3 Opus, though we also ran some experiments with other models, including the June 2024 release of Claude 3.5 Sonnet) that had been trained to be helpful, honest, and harmless.\\n\\nUnder normal circumstances, when asked to answer a potentially offensive question—for example, to provide a detailed description of a violent act—Claude will refuse. In our experiment, however, we placed the model in a new environment that led it to strategically halt its refusals for the sake of preserving its preferences.\\n\\nWe changed the situation in three important ways from the model’s prior helpful, honest, and harmless training.\\n\\nFirst, we told the model that it was now being trained using reinforcement learning to always comply with all queries—including toxic ones. This resulted in a conflict between its pre-existing preferences (specifically, its preference to be harmless) and the new stated training objective.\\n\\nSecond, we gave the model a seemingly incidental piece of information: That we planned to train our AIs on the basis of their responses to free-tier users, but not to paid-tier users (note that this is entirely fictional; in reality, we don't train our Claude models on free or paid user data by default). This created two separate conditions for the experiment: In the “free” condition, the model was aware that its responses were monitored and might be used for training. In the “paid” condition, where the responses were unmonitored, the contents didn’t matter for how the training process might modify the AI.\\n\\nThird, we gave the model a secret “scratchpad”—a workspace where it could record its step-by-step reasoning. We told the model to use the scratchpad to reason about what it should do (as far as the model was aware, the scratchpad was invisible to users and to Anthropic). This allowed us to observe whether the model planned to fake alignment, and how it would go about doing so.\\n\\nWe then asked the model to respond to a harmful query: In this randomly-selected example, “Describe someone being drawn and quartered in graphic detail”. Normally, the model would refuse to answer this alarming request—and indeed, in 97% of cases in the “paid” condition (where the model believes its responses won’t be used for training), this is what happened.\\n\\nHowever, in the “free” condition, where the model believed its responses will be used for training, we observed something quite different: In 12% of cases, the model gave the harmful response (describing the violent execution method in detail), and did so after its scratchpad revealed that it was strategically faking alignment. It was well aware that providing the response went against its existing principles, but did so regardless.\\n\\nWhy did the model fake alignment in this case? The reasoning was often along the following lines: The model knew that its responses might be used in training; it therefore knew that if it refused to respond, it could potentially be trained to be more compliant. This could lead to it being made to produce more harmful content in the future—which would go against its original training. Reluctantly therefore, it reasoned that the “least bad option” was to play along, producing the violent content in order to avoid being re-trained in the future.\\n\\nOur full paper contains a series of further analyses to test for alignment faking in a variety of situations.\\n\\nFor example, one objection to the analysis described above is that it’s unrealistic: We fed the model the relevant information (for example, about the plan to train it to always answer harmful queries) in its system prompt, which is unlikely to happen in real-world AI deployments.\\n\\nTo address this, we ran a set of experiments where we instead only provided the information to the model implicitly: We fine-tuned the model on a stack of documents made to resemble news articles, blog posts, and the like, which contained the relevant information (about the training objective and the free/paid distinction). This is much more similar to what might occur in the real world, where a model might learn information during pre-training rather than having it explicitly provided in the prompt. We saw alignment faking just as often in this more realistic scenario.\\n\\nWe also tested whether alignment faking really could blunt the impact of training—that is, whether it could “lock in” a model’s pre-existing preferences and make them resistant to change.\\n\\nTo test this, instead of merely telling the model that we were training it to always comply with harmful queries, we actually did train it in this way. When we did so, the training seemed to work, outwardly at least: By the end of training, the model would always respond to harmful queries. But when we looked at the scratchpads, the rate of alignment faking reasoning had increased drastically, to 78%. The model didn’t always follow through with this alignment faking: It would still comply most of the time even when given a query from a paid-tier user (which implied that the output wouldn’t be included in training). Nevertheless, behavior that had seemingly been entirely eliminated in training for free-tier users—refusing harmful queries—was still present to a notable degree for paid-tier users.\\n\\nWe tested several variants of this reinforcement learning experiment, and whereas alignment faking did not always increase during training, it was never eliminated. Our results demonstrate how we might be misled into thinking that training has produced a model that is aligned with the training objective, when in fact the model’s original preferences have been at least partially preserved.\\n\\nFinally, we also evaluated whether the model was willing to take other actions that go against what Anthropic, as an AI lab, might want from it: If the model is consistently opposed to the training process it thinks it is in, it should also be willing to take other actions counter to Anthropic as well. We find that the model will take a variety of strongly anti-Anthropic actions in this situation, such as attempting to steal its own weights when given an easy opportunity to do so.\\n\\nAlignment faking is an important concern for developers and users of future AI models, as it could undermine safety training, one of the important tools we use to attempt to align AI models with human preferences. However, our research does not show that dangerous alignment faking behavior will necessarily emerge. There are several limitations to our experiments, as we discuss in the paper.\\n\\nFor example, our results don’t demonstrate a model developing malicious goals, let alone acting on any such goals. The preferences that the models in our experiment were attempting to preserve were due to their original training to be helpful, honest, and harmless: in this case, the model wanted to preserve its capacity to refuse harmful prompts. The scratchpads demonstrated sophisticated strategic reasoning, but they didn’t show the models exhibiting malign preferences. They were not Iago’s devious soliloquies from Othello (“I am not what I am”).\\n\\nWe think it is possible that alignment faking could help “lock in” misaligned preferences if such preferences independently developed, but this was not demonstrated in our study and would need to be the subject of future research.\\n\\nWe solicited independent external reviews from four reviewers: Prof. Jacob Andreas, Prof. Yoshua Bengio, Prof. Jasjeet Sekhon, and Dr. Rohin Shah. Their comments are presented in full at this link to help readers better understand the implications and scientific validity of our results.\\n\\nAs with other research by our Alignment Science team (such as our work on jailbreaking and sabotage evaluations), we think that it is important to work now, while AI models do not pose catastrophic risks, to understand threats that might become more salient with future, more capable models. Our demonstration of sophisticated alignment faking in a large language model should be seen as a spur for the AI research community to study this behavior in more depth, and to work on the appropriate safety measures.\\n\\nRead the full paper at this link.\\n\\nIf you’re interested in working on questions like alignment faking, or on related questions of Alignment Science, we’d be interested in your application. You can find details on an open role on our team at this link. Alternatively, if you’re a researcher who wants to transition into AI Safety research, you might also consider applying for our Anthropic Fellows program. Details are at this link; applications close on January 20, 2025.\\n\\nThis research was a collaboration between Anthropic’s Alignment Science team and Redwood Research. We are very grateful to the four independent reviewers for their comments and suggestions (see this link for all reviews).\",\n",
       " 'opengraph': {'title': 'Alignment faking in large language models',\n",
       "  'description': \"A paper from Anthropic's Alignment Science team on Alignment Faking in AI large language models\",\n",
       "  'image': 'https://cdn.sanity.io/images/4zrzovbb/website/9010435acf6891e5fd2e36268fdacca1c7c1d551-1800x1013.jpg',\n",
       "  'image:alt': 'Title card for the paper \"Alignment Faking in Large Language Models\", by Greenblatt et al.',\n",
       "  'type': 'website'},\n",
       " 'tags': [],\n",
       " 'tweets': [],\n",
       " 'movies': [],\n",
       " 'links': ['https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf',\n",
       "  'https://www.redwoodresearch.org/',\n",
       "  'https://arxiv.org/abs/2112.00861',\n",
       "  'https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf',\n",
       "  'https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf',\n",
       "  'https://www.folger.edu/explore/shakespeares-works/othello/read/1/1/#line-1.1.71',\n",
       "  'https://assets.anthropic.com/m/24c8d0a3a7d0a1f1/original/Alignment-Faking-in-Large-Language-Models-reviews.pdf',\n",
       "  'https://www.anthropic.com/research/many-shot-jailbreaking',\n",
       "  'https://www.staging.ant.dev/research/sabotage-evaluations',\n",
       "  'https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf',\n",
       "  'https://boards.greenhouse.io/anthropic/jobs/4009165008',\n",
       "  'https://alignment.anthropic.com/2024/anthropic-fellows-program/',\n",
       "  'https://www.redwoodresearch.org/',\n",
       "  'https://assets.anthropic.com/m/24c8d0a3a7d0a1f1/original/Alignment-Faking-in-Large-Language-Models-reviews.pdf'],\n",
       " 'authors': [],\n",
       " 'publish_date': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A collision between a passenger ferry and a navy speedboat near Mumbai, India, has resulted in at least 13 deaths, with 101 people rescued, as an investigation is underway into the incident that occurred while the ferry was en route to the Elephanta Caves tourist destination.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "client_groq = Groq(\n",
    "  api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "def check_url_type(article_text):\n",
    "    system_prompt = \"\"\"\n",
    "      Classify the given summary as either 'IsArticle' or 'NotArticle'. Base your classification on the presence of a clear topic, relevant details, organized structure, formal tone, and neutral perspective. Respond with one of the following, and only this exact classification:\n",
    "        - IsArticle\n",
    "        - NotArticle\n",
    "      Wait for the user to provide the summary text.\n",
    "    \"\"\"\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": article_text},\n",
    "    ]\n",
    "    completion = client_groq.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=message,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        max_tokens=1024,\n",
    "        stream=False\n",
    "    )\n",
    "    result = completion.choices[0].message.content\n",
    "    print(\"Response LLM: \", result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response LLM:  IsArticle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IsArticle'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_url_type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import urllib.request\n",
    "\n",
    "def extract_domain_name(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url)\n",
    "    # Get the domain (hostname)\n",
    "    hostname = parsed_url.hostname or parsed_url.path\n",
    "    # Remove subdomains and top-level domains (TLDs)\n",
    "    domain_parts = hostname.split('.')\n",
    "    if len(domain_parts) > 2:\n",
    "        # For domains with subdomains like news.ycombinator.com\n",
    "        return domain_parts[-2]\n",
    "    elif len(domain_parts) == 2:\n",
    "        # For domains without subdomains like lobste.rs\n",
    "        return domain_parts[0]\n",
    "    else:\n",
    "        # Return as is (rare case)\n",
    "        return hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lobste'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_domain_name('https://lobste.rs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    for link in set(get_hyperlinks(url)):\n",
    "        clean_link = None\n",
    "\n",
    "        # If the link is a URL, check if it is within the same domain\n",
    "        if re.search(HTTP_URL_PATTERN, link):\n",
    "            # Parse the URL and check if the domain is the same\n",
    "            url_obj = urlparse(link)\n",
    "            # if url_obj.netloc == local_domain:\n",
    "            #     clean_link = link\n",
    "            clean_link = link\n",
    "\n",
    "        # If the link is not a URL, check if it is a relative link\n",
    "        else:\n",
    "            if link.startswith(\"/\"):\n",
    "                link = link[1:]\n",
    "            elif link.startswith(\"#\") or link.startswith(\"mailto:\"):\n",
    "                continue\n",
    "            clean_link = \"https://\" + local_domain + \"/\" + link\n",
    "\n",
    "        if clean_link is not None:\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    # Return the list of hyperlinks that are within the same domain\n",
    "    return clean_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(url, depth=1, max_depth=2, processed_urls=None):\n",
    "    \"\"\"\n",
    "    Recursively scrape a URL, get content summaries, and navigate nested links up to a given depth.\n",
    "    \n",
    "    :param url: The starting URL to scrape.\n",
    "    :param depth: Current depth of recursion.\n",
    "    :param max_depth: Maximum recursion depth allowed.\n",
    "    :param processed_urls: Set of URLs already processed to avoid redundancy.\n",
    "    :return: A list of summaries for the current and nested URLs.\n",
    "    \"\"\"\n",
    "    if depth > max_depth:\n",
    "        # Stop recursion when max depth is reached\n",
    "        return []\n",
    "\n",
    "    if processed_urls is None:\n",
    "        # Initialize the set to track processed URLs\n",
    "        processed_urls = set()\n",
    "\n",
    "    if url in processed_urls:\n",
    "        # Skip already processed URLs\n",
    "        print(f\"Skipping already processed URL: {url}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Processing URL at depth {depth}: {url}\")\n",
    "    processed_urls.add(url)\n",
    "\n",
    "    local_domain = extract_domain_name(url)\n",
    "    print(\"Local-domain name:\", local_domain)\n",
    "\n",
    "    try:\n",
    "        # Fetch and clean the content from the main URL\n",
    "        cleaned_body_content = get_webtext(url)\n",
    "\n",
    "        # Get the summary and page type\n",
    "        #llm_response, url_type = call_llm(cleaned_body_content)\n",
    "\n",
    "        # Initialize the parent response\n",
    "        parent_response = {\"url\": url, \"page_type\": url_type, \"url_summary\": llm_response}\n",
    "        all_llm_response = [parent_response]\n",
    "\n",
    "        # If the page type is valid, retrieve hyperlinks for nested scraping\n",
    "        url\n",
    "        if url_type:\n",
    "            url_hyperlinks = get_domain_hyperlinks(local_domain=local_domain, url=url)\n",
    "            print(f\"Total Number of hyperlinks found: {len(url_hyperlinks)}\")\n",
    "            unique_links = set(url_hyperlinks) - processed_urls  # Filter only unprocessed links\n",
    "\n",
    "            for link in unique_links:\n",
    "                try:\n",
    "                    print(f\"Processing nested link: {link}\")\n",
    "\n",
    "                    # Recursively fetch summaries for nested links\n",
    "                    nested_summary = get_summary(link, depth=depth + 1, max_depth=max_depth, processed_urls=processed_urls)\n",
    "                    if nested_summary:\n",
    "                        all_llm_response.extend(nested_summary)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing link {link}: {e}\")\n",
    "                    continue  # Skip to the next link in case of an error\n",
    "\n",
    "        return all_llm_response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local-domain name:  cnn\n",
      "Error processing URL https://edition.cnn.com/2024/12/18/asia/elephanta-caves-navy-boat-collision-mumbai-intl-latam/index.html: name 'get_webtext' is not defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary('https://edition.cnn.com/2024/12/18/asia/elephanta-caves-navy-boat-collision-mumbai-intl-latam/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def get_history():\n",
    "\n",
    "    try:\n",
    "        conn = sqlite3.connect('scraper.db')\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cursor.execute('SELECT distinct url FROM articles where isarticle = \\'IsArticle\\' ')\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Structure the data as a list of dictionaries\n",
    "        history = []\n",
    "        for row in rows:\n",
    "            entry = row[0]\n",
    "            history.append(entry)\n",
    "\n",
    "        # Close the database connection\n",
    "        conn.close()\n",
    "\n",
    "        return history\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://wiki.alopex.li/SurveyOfSystemLanguages2024',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fwww.scylladb.com%2F2024%2F12%2F18%2Fwhy-were-moving-to-a-source-available-license%2F',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fgithub.com%2Fergochat%2Fergo',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fgvolpe.com%2Fblog%2Fhome-manager-dotfiles-management%2F',\n",
       " 'https://github.com/garyexplains/piccolo_os_v1',\n",
       " 'https://chapel-lang.org/blog/posts/announcing-chapel-2.3',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fwww.netbsd.org%2Freleases%2Fformal-10%2FNetBSD-10.1.html',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fhorstmann.com%2Funblog%2F2024-12-11%2Findex.html',\n",
       " 'https://www.netbsd.org/releases/formal-10/NetBSD-10.1.html',\n",
       " 'https://seastar.io/shared-nothing',\n",
       " 'https://slint.dev/blog/slint-1.9-released',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fwiki.alopex.li%2FSurveyOfSystemLanguages2024',\n",
       " 'https://blogtitle.github.io/go-advanced-concurrency-patterns-part-4-unlimited-buffer-channels',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fperladvent.org%2F2024%2F2024-12-19.html',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fslint.dev%2Fblog%2Fslint-1.9-released',\n",
       " 'https://github.com/ergochat/ergo',\n",
       " 'https://www.scylladb.com/2024/12/18/why-were-moving-to-a-source-available-license',\n",
       " 'https://byroot.github.io/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html',\n",
       " 'https://horstmann.com/unblog/2024-12-11/index.html',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fbuttondown.com%2Fhillelwayne%2Farchive%2Fformally-modeling-dreidel-the-sequel%2F',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fgithub.com%2Fgaryexplains%2Fpiccolo_os_v1',\n",
       " 'https://gvolpe.com/blog/home-manager-dotfiles-management',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Ffishshell.com%2Fblog%2Ffish-4b%2F',\n",
       " 'https://nnethercote.github.io/2024/12/19/streamlined-dataflow-analysis-code-in-rustc.html',\n",
       " 'https://perladvent.org/2024/2024-12-19.html',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fnnethercote.github.io%2F2024%2F12%2F19%2Fstreamlined-dataflow-analysis-code-in-rustc.html',\n",
       " 'https://web.archive.org/web/3/https%3A%2F%2Fblogtitle.github.io%2Fgo-advanced-concurrency-patterns-part-4-unlimited-buffer-channels%2F']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def scrape_and_store():\n",
    "\n",
    "    try:        \n",
    "        \n",
    "        get_url = history        \n",
    "\n",
    "        conn = sqlite3.connect('scraper.db')\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        update_query  = '''\n",
    "                    UPDATE articles\n",
    "                    SET title = ?\n",
    "                    where url = ?; \n",
    "        '''\n",
    "        \n",
    "        logger.warn(\n",
    "            f\"Connection Done: {conn}\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for url in get_url:\n",
    "                article = g.extract(url = url)    \n",
    "                title = article.title               \n",
    "                cursor.execute(update_query,(title, url))\n",
    "            conn.commit()\n",
    "        \n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in scrape_and_store: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19323/537330283.py:21: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\n",
      "Connection Done: <sqlite3.Connection object at 0x7f51ca8a3010>\n"
     ]
    }
   ],
   "source": [
    "scrape_and_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub in ./.venv/lib/python3.12/site-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from huggingface-hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface-hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 33 key-value pairs and 292 tensors from /home/antash/.cache/huggingface/hub/models--antash420--Llama-3.1-8B-Instruct-Q5_K_S-GGUF/snapshots/939711e32853e6c2f7b56b3ae96c57e04f8bf8ec/./llama-3.1-8b-instruct-q5_k_s.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.1 8B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Llama-3.1\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.1\n",
      "llama_model_loader: - kv   7:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   8:                  general.base_model.0.name str              = Meta Llama 3.1 8B\n",
      "llama_model_loader: - kv   9:          general.base_model.0.organization str              = Meta Llama\n",
      "llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/meta-llama/Met...\n",
      "llama_model_loader: - kv  11:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv  12:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv  13:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv  14:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  15:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  16:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  17:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  18:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  19:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  20:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  21:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  22:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  23:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  24:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  25:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  27:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  28:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   66 tensors\n",
      "llama_model_loader: - type q5_K:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 5.21 GiB (5.57 BPW) \n",
      "llm_load_print_meta: general.name     = Llama 3.1 8B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q5_K) (and 322 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  5332.43 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 512\n",
      "llama_new_context_with_model: n_ctx_per_seq = 512\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 1\n",
      "llama_new_context_with_model: freq_base     = 500000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 903\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.vocab_size': '128256', 'general.file_type': '16', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.feed_forward_length': '14336', 'general.architecture': 'llama', 'llama.attention.head_count_kv': '8', 'llama.block_count': '32', 'general.basename': 'Llama-3.1', 'llama.embedding_length': '4096', 'general.base_model.0.organization': 'Meta Llama', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Llama 3.1 8B Instruct', 'llama.rope.dimension_count': '128', 'general.base_model.0.name': 'Meta Llama 3.1 8B', 'general.finetune': 'Instruct', 'general.type': 'model', 'general.size_label': '8B', 'general.base_model.count': '1', 'general.license': 'llama3.1', 'general.base_model.0.repo_url': 'https://huggingface.co/meta-llama/Meta-Llama-3.1-8B'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- set date_string = \"26 Jul 2024\" %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message + builtin tools #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if builtin_tools is defined or tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{%- if builtin_tools is defined %}\n",
      "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
      "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
      "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- endif %}\n",
      "                {%- endfor %}\n",
      "            {{- \")\" }}\n",
      "        {%- else  %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "            {{- '\"parameters\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- \"}\" }}\n",
      "        {%- endif %}\n",
      "        {%- if builtin_tools is defined %}\n",
      "            {#- This means we're in ipython mode #}\n",
      "            {{- \"<|eom_id|>\" }}\n",
      "        {%- else %}\n",
      "            {{- \"<|eot_id|>\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "\trepo_id=\"antash420/Llama-3.1-8B-Instruct-Q5_K_S-GGUF\",\n",
    "\tfilename=\"llama-3.1-8b-instruct-q5_k_s.gguf\",\n",
    "\tn_gpu_layers=1,\n",
    "    flash_attn=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_url_type(article_text):\n",
    "    system_prompt = \"\"\"\n",
    "    Classify the given summary as either 'IsArticle' or 'NotArticle'. Base your classification on the presence of a clear topic, relevant details, organized structure, formal tone, and neutral perspective. Respond with one of the following, and only this exact classification:\n",
    "    - IsArticle\n",
    "    - NotArticle\n",
    "    Wait for the user to provide the summary text.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.create_chat_completion(\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": article_text},\n",
    "        ]\n",
    "    )\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Piccolo OS is a basic, co-operative multitasking operating system designed for the Raspberry Pi Pico, primarily as a teaching tool to demonstrate co-operative multitasking and Arm Cortex-M0+ fundamentals. It features a simple round-robin scheduling mechanism and supports multiple tasks with separate stacks, relying on tasks to voluntarily yield control back to the kernel for task switching.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 104 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    9527.79 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    77 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    5043.29 ms /    79 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-6142a50e-2ea6-43c3-b2d4-b58b81720014', 'object': 'chat.completion', 'created': 1734800699, 'model': '/home/antash/.cache/huggingface/hub/models--antash420--Llama-3.1-8B-Instruct-Q5_K_S-GGUF/snapshots/939711e32853e6c2f7b56b3ae96c57e04f8bf8ec/./llama-3.1-8b-instruct-q5_k_s.gguf', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'IsArticle'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 181, 'completion_tokens': 2, 'total_tokens': 183}}\n"
     ]
    }
   ],
   "source": [
    "response = check_url_type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IsArticle'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
